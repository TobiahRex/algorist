{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Problems\n",
    "\n",
    "25 Practice Problems on Graphs\n",
    "\n",
    "---\n",
    "\n",
    "### 1.LC.210: **Course Schedule II** | `Medium`\n",
    "\n",
    "- [Video Solution](https://www.youtube.com/watch?v=EgI5nU9etnU&list=PLot-Xpze53ldBT_7QA8NVot219jFNr_GI&index=2)\n",
    "\n",
    "#### Solution Thoughts 🤔\n",
    "\n",
    "The problem describes a _dependency_ between courses. Dependencies should automatically prompt us to think in terms of a DAG's. Thinking divergently the tools we know of to operate on DAGs are\n",
    "\n",
    "- [Y] Topological Sort\n",
    "  - [N] BFS - optimality\n",
    "  - [Y] DFS - possibility\n",
    "  - [P] Arrival/Departure Accounting\n",
    "    - BackEdge, CrossEdge, ForwardEdge\n",
    "    - Iterative(med/hard) or Recursive(easy)\n",
    "  - [P] Vertex Coloring\n",
    "- [N] Strongly Connected Components - Classification\n",
    "- [N] Prims/Kruskals MST - optimality\n",
    "- [N] Eulerian Efficiency - optimality\n",
    "- [N] Shortest Paths - optimality\n",
    "  Given this elimination process we can be convergent now and say topological sort with a detection of a Back Edge should give us the solution we're looking for. Furthermore, a recursive dfs would be the easiest/fastest solution approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Back Edge:  1 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Solution:\n",
    "    def findOrder(self, n, courses):\n",
    "        adj_map = self.build_graph(n, courses)\n",
    "        arr, dep, topo = [0] * n, [0] * n, []\n",
    "        for course in range(n):\n",
    "            if not arr[course]:\n",
    "                has_cycle, _ = self.dfs(0, adj_map, course, arr, dep, topo)\n",
    "                if has_cycle:\n",
    "                    return []\n",
    "        return topo\n",
    "\n",
    "    def dfs(self, CLOCK, adj_map, u, arr, dep, topo):\n",
    "        CLOCK += 1\n",
    "        arr[u] = CLOCK\n",
    "        for v in adj_map.get(u):\n",
    "            if not arr[v]:\n",
    "                cycle, CLOCK = self.dfs(CLOCK, adj_map, v, arr, dep, topo)\n",
    "                if cycle:\n",
    "                    return True, CLOCK\n",
    "            elif not dep[v]:\n",
    "                print(\"Back Edge: \", u, v)\n",
    "                # cycle detected via Back-Edge\n",
    "                return True, CLOCK\n",
    "        CLOCK += 1\n",
    "        dep[u] = CLOCK\n",
    "        topo.append(u)\n",
    "        return False, CLOCK\n",
    "\n",
    "    def build_graph(self, n, edges):\n",
    "        adj_map = {i: set() for i in range(n)}\n",
    "        for u, v in edges:\n",
    "            adj_map[u].add(v)\n",
    "        return adj_map\n",
    "\n",
    "\n",
    "args = {\"n\": 3, \"edges\": [[1, 0], [1, 2], [0, 1]]}\n",
    "Solution().findOrder(*args.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our Solution\n",
    "\n",
    "- The above solution runs a bit slowly compared to online submissions:\n",
    "  - Time: 32% faster\n",
    "  - Space: 26% less\n",
    "\n",
    "#### Recommended Solution\n",
    "\n",
    "- The recommended solution by LeetCode is provided below. It uses the same technique of **Arrival** and **Departure** but abstracts the complexity of the numbering and extra memory to manage the entire list to something more terse; colors! The technique is called **Vertex Coloring**.\n",
    "  - WHITE = Unvisited\n",
    "  - GRAY = Arrived\n",
    "  - BLACK = Arrived & Departed\n",
    "- We could easily change the _Colors_ to be more intuitive to the approach we're already aware of: _Arrival & Departure_\n",
    "\n",
    "### Notes\n",
    "\n",
    "1. By default all vertces are WHITE\n",
    "2. If the node is unprocessed, then call dfs on it.\n",
    "3. Don't recurse further if we found a cycle already\n",
    "4. An edge to a GRAY vertex represents a cycle\n",
    "5. Recursion ends. We mark it as black\n",
    "6. A pair [a, b] in the input represents edge from b --> a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class Solution:\n",
    "    WHITE = 1  # unvisited\n",
    "    GRAY = 2  # arrived\n",
    "    BLACK = 3  # arrived & departed\n",
    "    is_possible = True\n",
    "\n",
    "    def findOrder(self, numCourses, prerequisites):\n",
    "        self.edges = self.build_graph(prerequisites)\n",
    "        self.colors = {k: Solution.WHITE for k in range(numCourses)}  # Note 1\n",
    "        self.topo = []\n",
    "        for u in range(numCourses):\n",
    "            if self.colors[u] == Solution.WHITE:  # Note 2\n",
    "                self.dfs(u)\n",
    "        return self.topo[::-1] if self.is_possible else []\n",
    "\n",
    "    def dfs(self, u):\n",
    "        if not self.is_possible:  # Note 3\n",
    "            return\n",
    "        self.colors[u] = Solution.GRAY\n",
    "        for v in self.edges.get(u, []):\n",
    "            if self.colors.get(v) == Solution.WHITE:\n",
    "                self.dfs(v)\n",
    "            elif self.colors.get(v) == Solution.GRAY:  # Note 4\n",
    "                self.is_possible = False\n",
    "        self.colors[u] = Solution.BLACK  # Note 5\n",
    "        self.topo.append(u)\n",
    "\n",
    "    def build_graph(self, prereqs):\n",
    "        edge_map = defaultdict(list)\n",
    "        for v, u in prereqs:\n",
    "            edge_map[u].append(v)\n",
    "        return edge_map\n",
    "\n",
    "\n",
    "args = {\"n\": 3, \"edges\": [[1, 0], [1, 2], [0, 1]]}\n",
    "Solution().findOrder(*args.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nice User Solution\n",
    "\n",
    "Credit `@Pythagoras_the_3rd` on LC.\n",
    "\n",
    "1. Create a pre-requisite adjacency map. Key's = course, and Values = pre-requisite course.\n",
    "2. Create a graph adjacency map. Key's = Pre-Requisite course. Values = the courses that depend on the Key.\n",
    "3. Locate a starting node - a course without dependencies.\n",
    "4. Pop off the Queue, add the Course pop'd to the `topo` result.\n",
    "5. If the `topo` length == number of courses, we know we're finished.\n",
    "6. Iterate over the neighbors for the given course, finding all neighbors that are blocked by the current node. Remove the current node from all those neighbor's pre-requisite lists. This signifies that we're taking the pre-requisite so it no longer blocks all the neighboring courses.\n",
    "7. Looking within the pre-requisite adj_map, if a neighbor has no more pre-requisites, then we know it's safe to take that course, so add it to the Queue.\n",
    "8. If we iterate over every legal course (get to the end of the Queue depth), and we haven't already returned, then we know it's impossible to take the course.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 0, 1]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import deque, defaultdict\n",
    "\n",
    "\n",
    "class Solution:\n",
    "    def findOrder(self, numCourses, prerequisites):\n",
    "        topo = []\n",
    "        preq = {i: set() for i in range(numCourses)}  # Note 1\n",
    "        graph = defaultdict(set)  # Note 2\n",
    "        for i, j in prerequisites:\n",
    "            preq[i].add(j)\n",
    "            graph[j].add(i)\n",
    "        q = deque([k for k, v in preq.items() if not v])  # Note 3\n",
    "        while q:\n",
    "            course = q.popleft()\n",
    "            topo.append(course)  # Note 4\n",
    "            if len(topo) == numCourses:  # Note 5\n",
    "                return topo\n",
    "            for cor in graph[course]:  # Note 6\n",
    "                preq[cor].remove(course)  # Note 7\n",
    "                if not preq[cor]:\n",
    "                    q.append(cor)\n",
    "        return []  # Note 8\n",
    "\n",
    "\n",
    "args = {\"n\": 3, \"edges\": [[1, 0], [1, 2], [0, 2]]}\n",
    "Solution().findOrder(*args.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.LC.133: **Clone A Graph** | `Medium`\n",
    "\n",
    "- Given a reference of a node in a **connected** undirected graph.\n",
    "  Return a **deep copy (clone)** of the graph.\n",
    "  Each node in the graph contains a value (`int`) and a list (`List[Node]`) of its neighbors. You must return the copy of the given node as a reference to the cloned graph.\n",
    "\n",
    "```python\n",
    "class Node {\n",
    "    public int val;\n",
    "    public List<Node> neighbors;\n",
    "}\n",
    "```\n",
    "\n",
    "<img src=\"https://imgur.com/m1hCiUX.png\" style=\"max-width:500px\">\n",
    "\n",
    "#### Solution Thoughts 🤔\n",
    "\n",
    "- Divergent Thinking\n",
    "  1. Traversing a graph and copying the values we find...\n",
    "     - [P] BFS seems like a good natural candidate\n",
    "     - [N] DFS seems like it should also work, but it's not super intuitive to me how to manage state.\n",
    "     - [P] DSU seems like it may work.\n",
    "       1. We could convert the `make_set` function to clone the nodes as we find them.\n",
    "       2. When we call `find(old_node.val)` if we don't find it, then we call `make_set`. We then iterate over each neighbor for `old_node` and call `union` with the parent copy we just made and each neighbor...it seems not so straight forward tho 😥\n",
    "  2. Using BFS the flow could be\n",
    "     1. Clone the starting node, and put on the queue. We only add cloned nodes onto the queue.\n",
    "     2. Each Q pop is meant to handle the neighbors of the node. If the neighbor is in a visited map, we know it's already been cloned, so take the clone and add it to a new `cloned_neighbors` list. Once we look thru all the neighbors, we assign the pop'd node's `neighbors` attr, to `cloned_neighbors`. If any neighbor is not in the `visited` map, we make a clone, add and enqueue it, and add it to the `visited` map.\n",
    "     3. <img src=\"https://imgur.com/nPJKjeh.png\" style=\"max-width:500px\"><br />This image shows the results of the cloned graph state, after having cloned the starting node `Sn1` and, and iterating over the neighbors of the starting node, and cloning `N2` and `N4`.\n",
    "     4. <img src=\"https://imgur.com/j4t0a2n.png\" style=\"max-width:300px\"><br />The Queue has `N2` and `N4` ready to be pop'd. But the `visited` map, has the cloned copies.\n",
    "     5. <img src=\"https://imgur.com/14krbKJ.png\" style=\"max-width:500px\"><br />The _Work Bench_ shows the process described. The old neighbors are shown in black, and then converted into clones (green). Those clones are appended to the _Cloned Neighbors_ list. Once all the neighbors are processed, `Sn1.neighbors` is assigned the clones list.\n",
    "     6. The remaining images show the lifecycle of the clone being formed. Pay attention to how the edge relationships are being modified over time.\n",
    "        - <img src=\"https://imgur.com/S5o7zsI.png\" style=\"max-width:200px\"> <img src=\"https://imgur.com/n7YBaiK.png\" style=\"max-width:200px\"> <img src=\"https://imgur.com/3zahcQE.png\" style=\"max-width:200px\"><br />\n",
    "- Time & Space Complexity:\n",
    "  1. Time = `O(|V| + |E|)`\n",
    "  2. Space = `O(|E|)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, val=0, neighbors=None):\n",
    "        self.val = val\n",
    "        self.neighbors = neighbors if neighbors is not None else []\n",
    "\n",
    "\n",
    "class Solution:\n",
    "    def cloneGraph(self, start_node: \"Node\") -> \"Node\":\n",
    "        if not start_node:\n",
    "            return start_node\n",
    "        visited = {}  # visited clones\n",
    "        cloned_start = Node(start_node.val, start_node.neighbors)\n",
    "        visited[cloned_start.val] = cloned_start\n",
    "        q = deque([cloned_start])\n",
    "        while q:\n",
    "            node = q.pop()\n",
    "            cloned_neighbors = []\n",
    "            for n in node.neighbors:\n",
    "                if n.val not in visited:\n",
    "                    clone = Node(n.val, n.neighbors)\n",
    "                    visited[clone.val] = clone\n",
    "                    cloned_neighbors.append(clone)\n",
    "                    q.appendleft(clone)\n",
    "                else:\n",
    "                    cloned_neighbors.append(visited.get(n.val))\n",
    "            node.neighbors = cloned_neighbors\n",
    "        return cloned_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "- Time: 20% faster 😅\n",
    "- Space: 77% Less 🏆 (b.c. no recursion)\n",
    "\n",
    "#### LC Solution | Recursive DFS\n",
    "\n",
    "**Notes**:\n",
    "\n",
    "1. Dictionary to save the visited node and it's respective clone as key and value respectively. This helps to avoid cycles.\n",
    "2. If the node was already visited before. Return the clone from the visited dictionary.\n",
    "3. Create a clone for the given node. Note that we don't have cloned neighbors as of now, hence [].\n",
    "4. The key is original node and value being the clone node.\n",
    "5. Iterate through the neighbors to generate their clones and prepare a list of cloned neighbors to be added to the cloned node.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, val, neighbors):\n",
    "        self.val = val\n",
    "        self.neighbors = neighbors\n",
    "\n",
    "\n",
    "class Solution(object):\n",
    "    def __init__(self):\n",
    "        self.visited = {}  # Note 1\n",
    "\n",
    "    def cloneGraph(self, node):\n",
    "        if not node:\n",
    "            return node\n",
    "        if node in self.visited:  # Note 2\n",
    "            return self.visited[node]\n",
    "        clone_node = Node(node.val, [])  # Note 3\n",
    "        self.visited[node] = clone_node  # Note 4\n",
    "        for n in node.neighbors:  # Note 5\n",
    "            clone_node.neighbors.append(self.cloneGraph(n))\n",
    "        return clone_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.LC.127: **Word Ladder** | `Hard`\n",
    "\n",
    "- Given two words, beginWord and endWord, and a dictionary wordList, return the number of words in the shortest transformation sequence from beginWord to endWord, or 0 if no such sequence exists.\n",
    "- ```python\n",
    "  # Example 1\n",
    "  Input: beginWord = \"hit\", endWord = \"cog\", wordList = [\"hot\",\"dot\",\"dog\",\"lot\",\"log\",\"cog\"]\n",
    "  Output: 5\n",
    "  Explanation: One shortest transformation sequence is \"hit\" -> \"hot\" -> \"dot\" -> \"dog\" -> cog\", which is 5 words long.\n",
    "\n",
    "  # Example 2\n",
    "  Input: beginWord = \"hit\", endWord = \"cog\", wordList = [\"hot\",\"dot\",\"dog\",\"lot\",\"log\"]\n",
    "  Output: 0\n",
    "  Explanation: The endWord \"cog\" is not in wordList, therefore there is no valid transformation sequence.\n",
    "  ```\n",
    "\n",
    "#### Divergent Thinking\n",
    "\n",
    "1. The question want's an _Optimal_ answer:\n",
    "\n",
    "- > **Shortest** transformation sequence\n",
    "\n",
    "2. Optimality = BFS, Dynamic Programming, Shortest Path algo's.\n",
    "\n",
    "- Technically dynamic programming is something like a DAG, and finding the shortest path in a DAG.\n",
    "\n",
    "3. Brute Force - Recursive n-ary tree.\n",
    "1. Given the `begin word` we can include/exclude a word from `wordList` if that `ith` letter matches the `ith letter` of the current parameter word. `hit` -> `hot` -> `h == h` so we call `f([hit, hot], [words from word list])` and `f([hit], [...rest of words from wordlist excluding 'hot'])`\n",
    "1. The solution here would be exponential. Something like `Order(N^k)` where `k` is the number of choices at `k` depth in the tree which varies from level to level depenthing on the `ith` letter being analyzed.\n",
    "1. Memoizing the solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution Approach | BFS + Dynamic Neighbors\n",
    "\n",
    "- **Time Complexity**\n",
    "  1. `O(N * (L + 26 * L + M)) ~ O(N*(L+M))`\n",
    "  2. For each word `(N)`, i need to look at each character with a length `L` (`N*L`) to determine if there's an edge to the end-word. Then I need to generate and compare all possible matches/neighbors of N (`M`). To generate those neighbors, i need to loop thru 26 characters, for the length of `N` (L times ~ `26 * L`).\n",
    "- **Notes**\n",
    "  1. Annoying edge case, to ensure work is worth being done otherwise quit early.\n",
    "  2. We save the distance travelled so far for a given Q'd node. If the problem was asking us to return the actual path travelled, this second argument would be a list of node values indicating the \"bread-crumb\" trail we took.\n",
    "  3. This logic could be done in a lot of places. However, i felt that it was most deterministically accurate to check directly after popping from the Q. This is akin to a recursive base-case check. As soon as we prepare to do some work, we first check if we've found the solution, otherwise, we continue.\n",
    "  4. This is **the major takeaway** from this problem; Typically we generate a graph by calculating it's edges **before** we start a traversal. However in this problem, we're calculating the next set of edges **on-the-fly**. I believe this technique is why this problem is considered `HARD` rather than `MEDIUM`.\n",
    "  5. As for HOW we're going about calculating the neighbors, this is quite interesting. Because we know we're looking for exactly a difference of 1 between word_1 and word_2, we know that the difference must exist within the actual alphabet. Meaning there's only 26 possible differences between two valid words having an edge between them. Therefore, we simply brute-force our way thru this list and generate every possible edge theoretically possible and validate the possibility against the given list of words. This is Asymptotically cheaper than looking thru every word, and comparing to every other word, every time we need to check for generate a neighbors list.\n",
    "  6. If however the word list is shorter than 26, then it's cheaper to look thru every word.\n",
    "  7. This is another key technqiue in this problem: we're _defining an edge by detecting an impossible edge_. If the difference in letter is greater than 1, the edge is impossible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "\n",
    "class Solution:\n",
    "    def ladderLength(self, beginWord, endWord, wordList):\n",
    "        word_set = set(wordList)\n",
    "        if endWord not in word_set:\n",
    "            return 0  # Note 1\n",
    "        visited = set([beginWord])\n",
    "        q = deque([(beginWord, 1)])  # Note 2\n",
    "        while q:\n",
    "            word, diff = q.pop()\n",
    "            if self.has_edge(word, endWord):\n",
    "                return diff + 1  # Note 3\n",
    "            for n in self.get_neighbors(word, word_set):  # Note 4\n",
    "                if n not in visited:\n",
    "                    visited.add(n)\n",
    "                    q.appendleft((n, diff + 1))\n",
    "        return 0\n",
    "\n",
    "    def get_neighbors(self, target, word_set):\n",
    "        neighbors = []\n",
    "        if len(word_set) > (26 * len(target)):  # Note 5\n",
    "            for code in range(ord(\"a\"), ord(\"z\") + 1):\n",
    "                for i in range(len(target)):\n",
    "                    word = target[:i] + chr(code) + target[i + 1 :]\n",
    "                    if word in word_set:\n",
    "                        neighbors.append(word)\n",
    "        else:\n",
    "            for w in word_set:  # Note 6\n",
    "                if self.has_edge(w, target):\n",
    "                    neighbors.append(w)\n",
    "        return neighbors\n",
    "\n",
    "    def has_edge(self, target, word):\n",
    "        diff = 0\n",
    "        for i in range(len(word)):  # Note 7\n",
    "            if target[i] != word[i]:\n",
    "                diff += 1\n",
    "                if diff > 1:\n",
    "                    return False\n",
    "        return diff == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LC Solution | BFS + Pre-Calculate All Neighbors\n",
    "\n",
    "- **Time Complexity**\n",
    "  1. `O((N * M) * M) ~ O(N * M^2)`\n",
    "  2. `N` = The length of `wordList`\n",
    "  3. `M` = The length of a neighbor word.\n",
    "  4. Expanation: In the worst case, we need to look thru every Vertex `N`, and for each vertex, we need to look thru all it's neighbors (`M`). For each of these neighbors, we need to look thru each character of the neighbor (`M^2`).\n",
    "- **Notes**\n",
    "  1. Dictionary to hold combination of words that can be formed, from any given word, by changing one letter at a time.\n",
    "  2. A Key is the generic word. A Value is a list of words which have the same intermediate generic word. Since the solution isn't asking us to return the actual list of words, then we don't need to use the 26 Alphabet character technique to specifically determine which words connect together. Rather we can use the `*` character, which improves the runtime considerably.\n",
    "  3. Generate all possible neighbor words, given the current pop'd Word by looping thru every i'th value and replacing the i'th char with an `*`.\n",
    "  4. Using the generated generic as a graph edge definition, we loop over all possible neighbors given the generic to find all possible neighbor nodes we could travel to.\n",
    "  5. If at any point if we find what we are looking for, i.e. the end word - we can return with the answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, deque\n",
    "\n",
    "\n",
    "class Solution(object):\n",
    "    def ladderLength(self, beginWord, endWord, wordList):\n",
    "        if endWord not in wordList:\n",
    "            return 0\n",
    "        L = len(beginWord)  # All words are same length\n",
    "        all_neighbors = defaultdict(list)  # Note 1\n",
    "        for word in wordList:\n",
    "            for i in range(L):\n",
    "                all_neighbors[word[:i] + \"*\" + word[i + 1 :]].append(word)  # Note 2\n",
    "        visited = set([beginWord])\n",
    "        queue = deque([(beginWord, 1)])\n",
    "        while queue:\n",
    "            current_word, diff = queue.pop()\n",
    "            for i in range(L):\n",
    "                edge = current_word[:i] + \"*\" + current_word[i + 1 :]  # Note 3\n",
    "                for n in all_neighbors[edge]:  # Note 4\n",
    "                    if n == endWord:\n",
    "                        return diff + 1  # Note 5\n",
    "                    if n not in visited:\n",
    "                        visited.add(n)\n",
    "                        queue.appendleft((n, diff + 1))\n",
    "                all_neighbors[edge] = []\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4.LC.417: **Pacific Atlantic Water Flow** | `Medium`\n",
    "\n",
    "- <img src=\"https://imgur.com/rFhj81x.png\" style=\"max-width:500px\">\n",
    "- ```python\n",
    "       Input: heights = [\n",
    "              [1,2,2,3,5],\n",
    "              [3,2,3,4,4],\n",
    "              [2,4,5,3,1],\n",
    "              [6,7,1,4,5],\n",
    "              [5,1,1,2,4]\n",
    "       ]\n",
    "       Output: [\n",
    "              [0,4], # row, col\n",
    "              [1,3],\n",
    "              [1,4],\n",
    "              [2,2],\n",
    "              [3,0],\n",
    "              [3,1],\n",
    "              [4,0]\n",
    "       ]\n",
    "       Explanation: The following cells can flow to the Pacific and Atlantic oceans, as shown below:\n",
    "       [0,4]: [0,4] -> Pacific Ocean\n",
    "              [0,4] -> Atlantic Ocean\n",
    "       [1,3]: [1,3] -> [0,3] -> Pacific Ocean\n",
    "              [1,3] -> [1,4] -> Atlantic Ocean\n",
    "       [1,4]: [1,4] -> [1,3] -> [0,3] -> Pacific Ocean\n",
    "              [1,4] -> Atlantic Ocean\n",
    "       [2,2]: [2,2] -> [1,2] -> [0,2] -> Pacific Ocean\n",
    "              [2,2] -> [2,3] -> [2,4] -> Atlantic Ocean\n",
    "       [3,0]: [3,0] -> Pacific Ocean\n",
    "              [3,0] -> [4,0] -> Atlantic Ocean\n",
    "       [3,1]: [3,1] -> [3,0] -> Pacific Ocean\n",
    "              [3,1] -> [4,1] -> Atlantic Ocean\n",
    "       [4,0]: [4,0] -> Pacific Ocean\n",
    "              [4,0] -> Atlantic Ocean\n",
    "       Note that there are other possible paths for these cells to flow to the Pacific and Atlantic oceans.\n",
    "  ```\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "1. Starting from the Pacific Ocean border, we can enque all nodes at that border. Then we BFS as long as the adjacent node has a value >= the current nodes value.\n",
    "2. Starting from the Atlantic Ocean border, we repeat step 1.\n",
    "3. The result will contain 2 different visited sets. We take the logical intersection of the two sets, and we have our answer.\n",
    "4. TimeComplexity: 2 _ rows _ cols ~ `O(rows * cols)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 4), (1, 3), (1, 4), (2, 2), (3, 0), (3, 1), (4, 0)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Solution:\n",
    "    def pacificAtlantic(self, heights):\n",
    "        rows, cols = len(heights), len(heights[0])\n",
    "        p_visited = set()\n",
    "        a_visited = set()\n",
    "        for i in range(rows):\n",
    "            self.get_nodes((i, 0), p_visited, heights)\n",
    "            self.get_nodes((i, cols - 1), a_visited, heights)\n",
    "        for i in range(cols):\n",
    "            self.get_nodes((0, i), p_visited, heights)\n",
    "            self.get_nodes((rows - 1, i), a_visited, heights)\n",
    "        return p_visited & a_visited\n",
    "\n",
    "    def get_nodes(self, start_node, visited, heights):\n",
    "        visited.add(start_node)\n",
    "        q = deque([start_node])\n",
    "        while q:\n",
    "            row, col = q.pop()\n",
    "            value = heights[row][col]\n",
    "            for i in [-1, 0, 1]:\n",
    "                for j in [-1, 0, 1]:\n",
    "                    if abs(i) == abs(j):\n",
    "                        continue\n",
    "                    r, c = row + i, col + j\n",
    "                    if (\n",
    "                        0 > r\n",
    "                        or r >= len(heights)\n",
    "                        or 0 > c\n",
    "                        or c >= len(heights[0])\n",
    "                        or heights[r][c] < value\n",
    "                    ):\n",
    "                        continue\n",
    "                    if (r, c) not in visited:\n",
    "                        node = (r, c)\n",
    "                        q.appendleft(node)\n",
    "                        visited.add((r, c))\n",
    "        return visited\n",
    "\n",
    "\n",
    "Solution().pacificAtlantic(\n",
    "    [\n",
    "        [1, 2, 2, 3, 5],\n",
    "        [3, 2, 3, 4, 4],\n",
    "        [2, 4, 5, 3, 1],\n",
    "        [6, 7, 1, 4, 5],\n",
    "        [5, 1, 1, 2, 4],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeetCode Solution\n",
    "\n",
    "- LC's solution uses DFS recursive, so there's a bit less boilerplate code, although the solution is a bit more expensive in terms of Time due to recursive call-stack.\n",
    "- **Notes**\n",
    "  1. Check if input is empty\n",
    "  2. Initialize variables, including sets used to keep track of visited cells\n",
    "  3. This cell is visited, so mark it\n",
    "  4. Check all 4 directions\n",
    "  5. Check if the new cell is within bounds. Check that the new cell has a higher or equal height, So that water can flow from the new cell to the old cell\n",
    "  6. Check that the new cell hasn't already been visited\n",
    "  7. Loop through each cell adjacent to the oceans and start a DFS\n",
    "  8. Find all cells that can reach both oceans, and convert to list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solution:\n",
    "    def pacificAtlantic(self, matrix):\n",
    "        if not matrix or not matrix[0]:\n",
    "            return []  # Note 1\n",
    "        num_rows, num_cols = len(matrix), len(matrix[0])  # Note 2\n",
    "        pacific_visited = set()\n",
    "        atlantic_visited = set()\n",
    "\n",
    "        def dfs(row, col, visited):\n",
    "            visited.add((row, col))  # Note 3\n",
    "            for x, y in [(1, 0), (0, 1), (-1, 0), (0, -1)]:  # Note 4\n",
    "                new_row, new_col = row + x, col + y\n",
    "                if (\n",
    "                    new_row < 0\n",
    "                    or new_row >= num_rows\n",
    "                    or new_col < 0\n",
    "                    or new_col >= num_cols\n",
    "                    or matrix[new_row][new_col] < matrix[row][col]\n",
    "                ):  # Note 5\n",
    "                    continue\n",
    "                if (new_row, new_col) not in visited:  # Note 6\n",
    "                    dfs(new_row, new_col, visited)\n",
    "\n",
    "        for i in range(num_rows):  # Note 7\n",
    "            dfs(i, 0, pacific_visited)\n",
    "            dfs(i, num_cols - 1, atlantic_visited)\n",
    "        for i in range(num_cols):\n",
    "            dfs(0, i, pacific_visited)\n",
    "            dfs(num_rows - 1, i, atlantic_visited)\n",
    "        return list(pacific_visited.intersection(atlantic_visited))  # Note 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5.LC.743: **Network Delay Time** | `Medium`\n",
    "\n",
    "You are given a network of n nodes, labeled from 1 to n. You are also given times, a list of travel times as directed edges times[i] = (ui, vi, wi), where ui is the source node, vi is the target node, and wi is the time it takes for a signal to travel from source to target.\n",
    "\n",
    "We will send a signal from a given node k. Return the minimum time it takes for all the n nodes to receive the signal. If it is impossible for all the n nodes to receive the signal, return -1.\n",
    "\n",
    "<img src=\"https://imgur.com/Z8TR3Yi.png\" style=\"max-width:500px\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    def __init__(self, edges, V):\n",
    "        self.V = V\n",
    "        self.adj_map = Graph.build_graph(V, edges)\n",
    "        self.visited = set()\n",
    "        self.distances = {}\n",
    "\n",
    "    def dijkstra(self, start):\n",
    "        self.visited.add(start)\n",
    "        self.distances[start] = 0\n",
    "        q = [start]\n",
    "        while q:\n",
    "            u = self.get_min(q)\n",
    "            self.visited.add(u)\n",
    "            for v, cost in self.adj_map.get(u):\n",
    "                distance_u = self.get_distance(u)\n",
    "                distance_v = self.get_distance(v)\n",
    "                if distance_v > distance_u + cost:\n",
    "                    self.distances[v] = distance_u + cost\n",
    "                    q.append(v)\n",
    "\n",
    "    def get_result(self, start):\n",
    "        unvisited = set(list(self.adj_map.keys())) - self.visited\n",
    "        max_delay = max(self.distances.values())\n",
    "        return -1 if max_delay in [float(\"inf\"), 0] or unvisited else max_delay\n",
    "\n",
    "    def get_distance(self, vertex):\n",
    "        if vertex in self.distances:\n",
    "            return self.distances.get(vertex)\n",
    "        self.distances[vertex] = float(\"inf\")\n",
    "        return self.distances.get(vertex)\n",
    "\n",
    "    def get_min(self, q):\n",
    "        for i in range(len(q) // 2 - 1, -1, -1):\n",
    "            self.heapify(q, i, len(q))\n",
    "        self.swap(q, 0, -1)\n",
    "        return q.pop()\n",
    "\n",
    "    def heapify(self, q, i, size):\n",
    "        min_i, l, r = i, 2 * i + 1, 2 * i + 2\n",
    "        distance_min = self.get_distance(q[min_i])\n",
    "        if l < size and self.get_distance(q[l]) < distance_min:\n",
    "            min_i = l\n",
    "        if r < size and self.get_distance(q[r]) < distance_min:\n",
    "            min_i = r\n",
    "        if min_i != i:\n",
    "            self.swap(q, min_i, i)\n",
    "            self.heapify(q, min_i, size)\n",
    "\n",
    "    @staticmethod\n",
    "    def swap(a, l, r):\n",
    "        a[l], a[r] = a[r], a[l]\n",
    "\n",
    "    @staticmethod\n",
    "    def build_graph(v, edges):\n",
    "        adj_map = {i: set() for i in range(1, v + 1)}\n",
    "        for u, v, c in edges:\n",
    "            adj_map[u].add((v, c))\n",
    "        return adj_map\n",
    "\n",
    "\n",
    "class Solution:\n",
    "    def networkDelayTime(self, times, n, k):\n",
    "        g = Graph(times, n)\n",
    "        g.dijkstra(k)\n",
    "        return g.get_result(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 6.LC.79: **Word Search** | `Medium`\n",
    "\n",
    "Given an m x n grid of characters board and a string word, return true if word exists in the grid.\n",
    "\n",
    "The word can be constructed from letters of sequentially adjacent cells, where adjacent cells are horizontally or vertically neighboring. The same letter cell may **not** be used more than once.\n",
    "\n",
    "- **Example 1**\n",
    "\n",
    "  - <img src=\"https://imgur.com/jBK0e4A.png\" styl=\"max-width:500px\">\n",
    "  - ```\n",
    "    Input: board = [[\"A\",\"B\",\"C\",\"E\"],[\"S\",\"F\",\"C\",\"S\"],[\"A\",\"D\",\"E\",\"E\"]], word = \"ABCCED\"\n",
    "    Output: true\n",
    "    ```\n",
    "\n",
    "- **Example 2**\n",
    "\n",
    "  - <img src=\"https://imgur.com/cIAbhLi.png\" styl=\"max-width:500px\">\n",
    "  - ```\n",
    "    Input: board = [[\"A\",\"B\",\"C\",\"E\"],[\"S\",\"F\",\"C\",\"S\"],[\"A\",\"D\",\"E\",\"E\"]], word = \"SEE\"\n",
    "    Output: true\n",
    "    ```\n",
    "\n",
    "- **Example 3**\n",
    "  - <img src=\"https://imgur.com/C5DK0aW.png\" styl=\"max-width:500px\">\n",
    "  - ```\n",
    "    Input: board = [[\"A\",\"B\",\"C\",\"E\"],[\"S\",\"F\",\"C\",\"S\"],[\"A\",\"D\",\"E\",\"E\"]], word = \"ABCB\"\n",
    "    Output: false\n",
    "    ```\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "- Divergent Thinking\n",
    "  1. We have a path and we want to find a specific path\n",
    "  2. BFS, DFS, DSU\n",
    "     - [3] DFS: Iterative\n",
    "       - We traverse, and only put on the stack, letters matching the next adjacent character.\n",
    "       - Time Complexity: (rows \\* cols) + len(word)\n",
    "       - **WONT WORK** Because we need to use backtracking. Backtracking is extremely difficult and hard to produce in an iterative solution. In recursion however, it's very simple.\n",
    "     - [2] BFS\n",
    "       - Because we know the adjacent letters to the previous letters.\n",
    "       - We could prioritize nodes in the Queue, to be the next adjacent letter.\n",
    "       - Time Complexity: (rows \\* cols) + len(word)\n",
    "     - 2] Adjacency Map\n",
    "       - Build an adj_map, {key: value} = {(row, col): set((row, col)...)}\n",
    "       - Because we have the target path, we can traverse thru the word, and look for an edge between word[n-1] to word[n]\n",
    "       - Time Complexity: (rows \\* cols) + len(word)\n",
    "     - [1] DSU\n",
    "- Convergent Thinking\n",
    "  1. Because all Time Complexities are equal, then we can prioritize based on min-code for fastest implementation.\n",
    "  2. Afterward, perhaps a more idiomatic approach would be\n",
    "\n",
    "#### NOTES: Iterative DFS + Backtracking | `Failed Attempt`\n",
    "\n",
    "1. Converting given word into dictionary where char index is key, and char is value.\n",
    "2. We initiate a DFS if the current char is the starting char of the target word. Similar to a Connected Components detection technique.\n",
    "3. If DFS returns True, we know the answer is found.\n",
    "4. We save the board coords (i, j) of the char we enqueued last. We need these values, to detect adjacent neighbors, after pop'ing\n",
    "5. We simply do a spiral detection around the target coordinates, and if i == j, then it's a diagonal so skip it.\n",
    "6. If the neighbor coordinate is illegal/out-of-bounds, or if the neighbor coordinate is in bounds, but the character is not int the target word, then skip it.\n",
    "7. If we get this far, we know the neighbor character is in the target word, but we need to also make sure, it's the NEXT character in the sequence. To determine what character is next in the sequence, we take the previous character's index from the stack pop, and simply increment by 1 to find the next target character. If that target character, matches the neighbor character, then we append to the stack.\n",
    "8. If the previous character's index value is equal to the last index in the target word, we know we've found that last character in the word, so we can eject early.\n",
    "9. If we haven't ejected early by now, then we know the DFS traversal, did not find the entire word in order.\n",
    "\n",
    "---\n",
    "\n",
    "10. Marking a node as visited, won't work because we need to be able to backtrack. There's quite a bit of tricks to try out, but it's extremely difficult and hard to explain. If DFS backtracking is what we need, then it's deterministically easier to simply build a recursive DFS with backtracking. When we want to backtrack, we simply pop off from the visited set, the faulty node we tried to go. The \"state\" of neighbors is saved in the call stack, so we can continue iterating from where we were one level up in the call stack.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "\n",
    "class Solution:\n",
    "    def exist(self, board, word) -> bool:\n",
    "        word_dict = {i: letter for i, letter in enumerate(list(word))}  # Note 1\n",
    "        word_set = set(list(word))\n",
    "        result = False\n",
    "        for i, r in enumerate(board):\n",
    "            for j, c in enumerate(r):\n",
    "                if c == word[0]:  # Note 2\n",
    "                    result = self.dfs(board, (i, j), word_dict, word_set)\n",
    "                    if result:\n",
    "                        return result  # Note 3\n",
    "        return result\n",
    "\n",
    "    def dfs(self, board, coords, word_dict, word_set):\n",
    "        visited = set([coords])\n",
    "        stack = deque([(*coords, 0)])  # Note 4\n",
    "        while stack:\n",
    "            progress = False\n",
    "            r, c, prev_i = stack.pop()\n",
    "            visited.add((r, c))\n",
    "            if len(visited) == len(word_dict):  # Note 8\n",
    "                return True\n",
    "            for i in [-1, 0, 1]:\n",
    "                for j in [-1, 0, 1]:\n",
    "                    if abs(i) == abs(j):\n",
    "                        continue  # Note 5\n",
    "                    row, col = r + i, c + j\n",
    "                    if (\n",
    "                        0 > row\n",
    "                        or row >= len(board)\n",
    "                        or 0 > col\n",
    "                        or col >= len(board[0])\n",
    "                        or board[row][col] not in word_set\n",
    "                        or (row, col) in visited\n",
    "                    ):\n",
    "                        continue  # Note 6\n",
    "                    n_char = board[row][col]\n",
    "                    target_char = word_dict.get(prev_i + 1)\n",
    "                    if n_char == target_char:  # Note 7\n",
    "                        visited.add((row, col))\n",
    "                        stack.appendleft((row, col, prev_i + 1))\n",
    "                        progress = True\n",
    "            if not progress:\n",
    "                visited.remove((r, c))\n",
    "        return False  # Note 9\n",
    "\n",
    "\n",
    "Solution().exist(\n",
    "    [[\"A\", \"B\", \"C\", \"E\"], [\"S\", \"F\", \"E\", \"S\"], [\"A\", \"D\", \"E\", \"E\"]], \"ABCESEEEFS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTES: Recursive DFS + Backtracking | `Success Attempt`\n",
    "\n",
    "1. Because we're using recursion, it's easiest to attach all the persistent state to the Class instance so we can have a clean recursive function signature.\n",
    "2. We initiate the dfs based on if the current character we're looking at, is equal to the first char in the target word.\n",
    "3. This is where we either return True up the call-stack because we're finished, or we backtrack. Backtracking is demonstrated by removing the current row and col from the visited set. This allows us to revisit the node from some other direction in the future.\n",
    "4. This is the only location where we return True: whenever we know we've found the last character in the word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Solution:\n",
    "    def exist(self, board, word) -> bool:\n",
    "        self.board = board\n",
    "        self.word_dict = {i: letter for i, letter in enumerate(list(word))}  # Note 1\n",
    "        self.word_set = set(list(word))\n",
    "        self.last_ix = len(word) - 1\n",
    "        self.rows = len(self.board)\n",
    "        self.cols = len(self.board[0])\n",
    "        # Note 1\n",
    "        for i, r in enumerate(board):\n",
    "            for j, c in enumerate(r):\n",
    "                if c == word[0]:  # Note 2\n",
    "                    if self.dfs(0, i, j, set([(i, j)])):\n",
    "                        return True\n",
    "        return False\n",
    "\n",
    "    def dfs(self, ix, r, c, visited):\n",
    "        if ix == self.last_ix:\n",
    "            return True  # Note 4\n",
    "        visited.add((r, c))\n",
    "        for i, j in [(0, -1), (0, 1), (1, 0), (-1, 0)]:\n",
    "            row, col = r + i, c + j\n",
    "            if (\n",
    "                0 > row\n",
    "                or row >= self.rows\n",
    "                or 0 > col\n",
    "                or col >= self.cols\n",
    "                or self.board[row][col] not in self.word_set\n",
    "                or (row, col) in visited\n",
    "            ):\n",
    "                continue\n",
    "            n_char = self.board[row][col]\n",
    "            target_char = self.word_dict.get(ix + 1)\n",
    "            if n_char == target_char:\n",
    "                # Note 3\n",
    "                if self.dfs(ix + 1, row, col, visited):\n",
    "                    return True\n",
    "                visited.remove((row, col))\n",
    "        return False\n",
    "\n",
    "\n",
    "Solution().exist(\n",
    "    [\n",
    "        [\"A\", \"A\", \"A\", \"A\", \"A\", \"A\"],\n",
    "        [\"A\", \"A\", \"A\", \"A\", \"A\", \"A\"],\n",
    "        [\"A\", \"A\", \"A\", \"A\", \"A\", \"A\"],\n",
    "        [\"A\", \"A\", \"A\", \"A\", \"A\", \"A\"],\n",
    "        [\"A\", \"A\", \"A\", \"A\", \"A\", \"A\"],\n",
    "        [\"A\", \"A\", \"A\", \"A\", \"A\", \"A\"],\n",
    "    ],\n",
    "    \"AAAAAAAAAAAAAAB\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 7.LC.463: **Island Perimeter** | `Easy`\n",
    "\n",
    "#### Solution Approach | DFS + Increment when no Neighbor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 14.LC.778: **Swim in Rising Water** | `Hard`\n",
    "\n",
    "#### Solution Approach | Dijkstra\n",
    "\n",
    "- Divergent Thinking\n",
    "  - BFS - Min-Cost path = Dijkstra. But we have to wait to pop off the Queue until t >= the next priorty value.\n",
    "  - DFS? - if so, we'd need to add backtracking. We pick the smallest value node, from all of the neighbors, and if that smallest neighbor is larger than t, then we assign t to that value. If the smallest neighbor is smaller than t, then we traverse without updating t. However, this is a bit more complicated so...Dijkstra seems more straight forward?\n",
    "  - DSU? - we make a union of current_cell + min_adjacent_cell. If after the union, the grid[-1][-1] location shares the same parent with the grid[0][0] location, then we should have our answer.\n",
    "- Convergent Thinking\n",
    "  - I'm a bit more comfortable writing the Dijkstra approach. However, TC: DSU may be better in **Best-Case**, but all choices should share the **same Worst-Case** = `O(n^2*logn)`.\n",
    "\n",
    "1. Constraints say all values are unique, so simpler to track values, rather than coordinates, but either works.\n",
    "2. `heapq` will sort on the first value, in a multi-value tuple, so we need to use the cell value in the first spot.\n",
    "3. We peak (not pop) from the Q. `peak[1][2]` is the \"peak'd nodes value\", which compare to `t`, ensuring it's the right time add travel further. If it's not the right time, then increment `t` by 1 while we \"wait\".\n",
    "4. Check to see if the pop'd node is the target destination: grid[-1][-1], if so, we're done\n",
    "5. grid[row][col] = the next node's value & the sorting key as mentioned earlier. The `heapq` will take care of \"heapifying\" for us.\n",
    "6. Optional techqniue: Dynamically generates the list of adjacent cells: `[(-1, 0), (0, -1), (0, 1), (1, 0)]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "\n",
    "class Solution:\n",
    "    adj_cells = [\n",
    "        (i, j) for i in [-1, 0, 1] for j in [-1, 0, 1] if abs(i) != abs(j)\n",
    "    ]  # Note 6\n",
    "\n",
    "    def swimInWater(self, grid):\n",
    "        n, t = len(grid), 0\n",
    "        visited = set([grid[0][0]])  # Note 1\n",
    "        pQ = [(grid[0][0], 0, 0)]  # Note 2\n",
    "        while pQ:\n",
    "            peak = pQ[0]\n",
    "            if grid[peak[1]][peak[2]] > t:  # Note 3\n",
    "                t += 1\n",
    "                continue\n",
    "            _, row, col = heapq.heappop(pQ)\n",
    "            for dx, dy in [(-1, 0), (0, -1), (0, 1), (1, 0)]:\n",
    "                r, c = row + dx, col + dy\n",
    "                in_bounds = 0 <= r < n and 0 <= c < n\n",
    "                if in_bounds and grid[r][c] not in visited:\n",
    "                    if r == c == n - 1:\n",
    "                        return t  # Note 4\n",
    "                    heapq.heappush(pQ, (grid[r][c], r, c))  # Note 5\n",
    "                    visited.add(grid[r][c])\n",
    "        return t\n",
    "\n",
    "\n",
    "Solution().swimInWater(\n",
    "    [\n",
    "        [0, 1, 2, 3, 4],\n",
    "        [24, 23, 22, 21, 5],\n",
    "        [12, 13, 14, 15, 16],\n",
    "        [11, 17, 18, 19, 20],\n",
    "        [10, 9, 8, 7, 6],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Solution using DSU\n",
    "class DSU(object):\n",
    "    def __init__(self, N):\n",
    "        self.par = list(range(N))\n",
    "        self.rnk = [0] * N\n",
    "\n",
    "    def find(self, x):\n",
    "        if self.par[x] != x:\n",
    "            self.par[x] = self.find(self.par[x])\n",
    "        return self.par[x]\n",
    "\n",
    "    def union(self, x, y):\n",
    "        p1, p2 = self.find(x), self.find(y)\n",
    "        if p1 != p2:\n",
    "            if self.rnk[p1] < self.rnk[p2]:\n",
    "                p1, p2 = p2, p1\n",
    "            self.par[p2] = p1\n",
    "            self.rnk[p1] += 1\n",
    "\n",
    "\n",
    "class Solution:\n",
    "    REACHABLE = 1\n",
    "\n",
    "    def swimInWater(self, grid):\n",
    "        d, N = {}, len(grid)\n",
    "        for i, j in product(range(N), range(N)):\n",
    "            d[grid[i][j]] = (i, j)\n",
    "        dsu = DSU(N * N)\n",
    "        grid = [[0] * N for _ in range(N)]\n",
    "        for i in range(N * N):\n",
    "            _x, _y = d[i]\n",
    "            grid[_x][_y] = self.REACHABLE\n",
    "            for dx, dy in [[0, 1], [0, -1], [1, 0], [-1, 0]]:\n",
    "                x, y = _x + dx, _y + dy\n",
    "                out_of_bounds = N > x >= 0 and N > y >= 0\n",
    "                if not out_of_bounds and grid[x][y] == 1:\n",
    "                    dsu.union(x * N + y, _x * N + _y)\n",
    "\n",
    "            if dsu.find(0) == dsu.find(N * N - 1):\n",
    "                return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 8.LC.1466: **Reorder Routes to Make All Paths Lead to City** | `Medium`\n",
    "\n",
    "##### Solution Approach | DSU\n",
    "\n",
    "1. Sink - we want to point all nodes to the sink.\n",
    "2. DSU\n",
    "   - we want `0` to be the last parent\n",
    "   - we build the original graph\n",
    "   - we start with node zero as the parent & rank: Infinity\n",
    "   - because some nodes will have no parents, we'll need to use a connected component detection technique\n",
    "3. Algo Steps\n",
    "   - Build graph\n",
    "   - Traverse through the graph one-connected component at a time.\n",
    "   - Enque the start node\n",
    "   - Pop from the Q:\n",
    "     - if parent of node is not 0, then perform union. increment counter\n",
    "     - Union the pop'd node's set, with 0.\n",
    "   - Enque the neighbors of the pop'd node.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import deque\n",
    "from giant_input import giant_args\n",
    "\n",
    "\n",
    "class DSU:\n",
    "    def __init__(self, n):\n",
    "        self.parents = [None] * n\n",
    "        self.rank = [0] * n\n",
    "        self.rank[0] = float(\"inf\")\n",
    "\n",
    "    def make_set(self, v):\n",
    "        self.parents[v] = v\n",
    "        self.rank[v] = 1\n",
    "\n",
    "    def find_parent(self, v):\n",
    "        if self.parents[v] == v:\n",
    "            return v\n",
    "        self.parents[v] = self.find_parent(self.parents[v])\n",
    "        return self.parents[v]\n",
    "\n",
    "    def union(self, v1, v2):\n",
    "        p1, p2 = self.find_parent(v1), self.find_parent(v2)\n",
    "        if p1 != p2:\n",
    "            if self.rank[p2] > self.rank[p1]:\n",
    "                p1, p2 = p2, p1\n",
    "            self.parents[p2] = p1\n",
    "            self.rank[p1] += 1\n",
    "\n",
    "\n",
    "class Solution:\n",
    "    def minReorder(self, n, connections):\n",
    "        dsu = DSU(n)\n",
    "        for i in range(n):\n",
    "            dsu.make_set(i)\n",
    "        count = 0\n",
    "        q = deque(connections)\n",
    "        while q:\n",
    "            u, v = q.pop()\n",
    "            if 0 in [v, dsu.find_parent(v)]:  # no count: road is pointing to 0\n",
    "                dsu.union(0, u)\n",
    "            elif 0 in [\n",
    "                u,\n",
    "                dsu.find_parent(u),\n",
    "            ]:  # add count: road was pointing away from 0\n",
    "                count += 1\n",
    "                dsu.union(u, v)\n",
    "            # else:\n",
    "            #     q.appendleft([u, v])\n",
    "        return count\n",
    "\n",
    "\n",
    "Solution().minReorder(6, [[0, 1], [1, 3], [2, 3], [4, 0], [4, 5]])\n",
    "# Solution().minReorder(*giant_args.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int minReorder(int n, vector<vector<int>>& connections) {\n",
    "    parent=vector<int>(n);\n",
    "    size=vector<int>(n);\n",
    "    for(int i=0;i<n;i++){\n",
    "        make_set(i);\n",
    "    }\n",
    "    for(int i=0;i<connections.size();i++){\n",
    "        if(connections[i][1]==0){\n",
    "            union_set(connections[i][1],connections[i][0]);\n",
    "        }\n",
    "    }\n",
    "    int count=0;\n",
    "        while(size[0]<=n-1){\n",
    "            for(int i=0;i<connections.size();i++){\n",
    "                if(find_par(connections[i][1])==0){\n",
    "                    union_set(connections[i][1],connections[i][0]);\n",
    "                }\n",
    "                else if(find_par(connections[i][0])==0){\n",
    "                    count++;\n",
    "                    union_set(connections[i][0],connections[i][1]);\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        return count;\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 9.LC.261: **Graph Valid Tree** | `Easy`\n",
    "\n",
    "##### Solution Approach | Vertex Coloring or BackEdge detection\n",
    "---\n",
    "\n",
    "### 10.LC.684: **Redundant Connections** | `Medium`\n",
    "\n",
    "#### Solution Approach | Visited Repeat\n",
    "\n",
    "---\n",
    "\n",
    "### 11.LC.212: **Word Search II** | `Hard`\n",
    "\n",
    "#### Solution Approach | Connected Components + Caching?\n",
    "\n",
    "---\n",
    "\n",
    "### 12.LC.269: **Alien Dictionary** | `Hard`\n",
    "\n",
    "#### Solution Approach | Topological Sorting + Pre-Post Visit\n",
    "\n",
    "---\n",
    "\n",
    "### 13.LC.1584: **Min Cost to Connect All Points** | `Medium`\n",
    "\n",
    "#### Solution Approach | Dijkstra + Every Unvisited Neighbor\n",
    "\n",
    "---\n",
    "\n",
    "### 15.LC.286: **Walls & Gates** | ``\n",
    "\n",
    "#### Solution Approach |\n",
    "\n",
    "---\n",
    "\n",
    "### 16.LC.130: **Surrounded Regions** | ``\n",
    "\n",
    "#### Solution Approach |\n",
    "\n",
    "---\n",
    "\n",
    "### 17.LC.787: **Cheapest Flights Within K Stops** | ``\n",
    "\n",
    "#### Solution Approach |\n",
    "\n",
    "---\n",
    "\n",
    "### 18.LC.695: **Max Area of Island** | ``\n",
    "\n",
    "#### Solution Approach |\n",
    "\n",
    "---\n",
    "\n",
    "### 19.LC.332: **Reconstruct Itinerary** | ``\n",
    "\n",
    "#### Solution Approach |\n",
    "\n",
    "---\n",
    "\n",
    "### 20.LC.994: **Rotting Oranges** | ``\n",
    "\n",
    "#### Solution Approach |\n",
    "\n",
    "---\n",
    "\n",
    "### 21.LC.329: **Longest Increasing Path in a Matrix** | ``\n",
    "\n",
    "#### Solution Approach |\n",
    "\n",
    "---\n",
    "\n",
    "### 22.LC.909: **Snakes & Ladders** | ``\n",
    "\n",
    "#### Solution Approach |\n",
    "\n",
    "---\n",
    "\n",
    "### 23.LC.752: **Open the Lock** | ``\n",
    "\n",
    "#### Solution Approach |\n",
    "\n",
    "---\n",
    "\n",
    "### 24.LC.934: **Shortest Bridge** | ``\n",
    "\n",
    "#### Solution Approach |\n",
    "\n",
    "---\n",
    "\n",
    "### 25.LC.802: **Find Eve-----------ntual Safe States** | ``\n",
    "\n",
    "#### Solution Approach |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7567341d4109f7d7c109ca0cef11eb54bdf88081d7a72c6faa88d24a2db59b1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
